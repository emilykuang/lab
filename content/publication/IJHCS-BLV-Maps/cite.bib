@article{10.1016/j.ijhcs.2025.103682,
title = {LLM-powered assistant with electrotactile feedback to assist blind and low vision people with maps and routes preview},
journal = {International Journal of Human-Computer Studies},
volume = {207},
pages = {103682},
year = {2026},
issn = {1071-5819},
doi = {10.1016/j.ijhcs.2025.103682},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925002393},
author = {Chutian Jiang and Yinan Fan and Junan Xie and Emily Kuang and Kaihao Zhang and Mingming Fan},
keywords = {Blind and low vision people, Electrotactile assistive tool, Maps and routes preview},
abstract = {Previewing routes to unfamiliar destinations is a crucial task for many blind and low vision (BLV) individuals to ensure safety and confidence before their journey. While prior work has primarily supported navigation during travel, less research has focused on how best to assist BLV people in previewing routes on a map. We designed a novel electrotactile system around the fingertip and the Trip Preview Assistant (TPA) to convey map elements, route conditions, and trajectories. TPA harnesses large language models (LLMs) to dynamically control and personalize electrotactile feedback, enhancing the interpretability of complex spatial map data for BLV users. In a user study with twelve BLV participants, our system demonstrated improvements in efficiency and user experience for previewing maps and routes. This work contributes to advancing the accessibility of visual map information for BLV users when previewing trips.}
}